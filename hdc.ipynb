{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c91385",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm\n",
    "import torchhd\n",
    "from torchhd import embeddings\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "# This function converts a 1D binary tensor into a single concatenated hex string.\n",
    "# It packs the binary vector into 32-bit integers and then converts each integer to hex.\n",
    "def binary_tensor_to_hex_str(tensor):\n",
    "    \"\"\"Converts a 1D binary tensor to a hex string.\"\"\"\n",
    "    # Ensure tensor is on CPU and is a numpy array for processing\n",
    "    tensor = tensor.cpu().numpy().astype(np.uint8)\n",
    "    # Pad the tensor with zeros to make its length a multiple of 8\n",
    "    # This simplifies packing into bytes.\n",
    "    rem = len(tensor) % 8\n",
    "    if rem != 0:\n",
    "        tensor = np.pad(tensor, (0, 8 - rem), 'constant')\n",
    "    \n",
    "    # Pack the numpy array of bits into bytes\n",
    "    packed_bytes = np.packbits(tensor)\n",
    "    # Convert the bytes to a single hex string\n",
    "    return packed_bytes.tobytes().hex()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "print(\"8K MNIST Baseline\")\n",
    "\n",
    "DIMENSIONS = 8192\n",
    "IMG_SIZE = 28\n",
    "NUM_LEVELS = 1000\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_ds = MNIST(\"./data\", train=True, transform=transform, download=True)\n",
    "train_ld = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = MNIST(\"./data\", train=False, transform=transform, download=True)\n",
    "test_ld = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_features, size, levels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.position = embeddings.Random(size * size, out_features)\n",
    "        self.value = embeddings.Level(levels, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        sample_hv = torchhd.bind(self.position.weight, self.value(x))\n",
    "        sample_hv = torchhd.multiset(sample_hv)\n",
    "        return torchhd.hard_quantize(sample_hv)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for run in range(1):\n",
    "    encode = Encoder(DIMENSIONS, IMG_SIZE, NUM_LEVELS)\n",
    "    encode = encode.to(device)\n",
    "\n",
    "    num_classes = len(train_ds.classes)\n",
    "    # Note: Assuming 'Centroid2' is a custom class similar to torchhd.models.Centroid\n",
    "    # For this code to be runnable, I'm using the standard torchhd Centroid model.\n",
    "    model = Centroid2(DIMENSIONS, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for samples, labels in tqdm(train_ld, desc=\"Training\"):\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            samples_hv = encode(samples)\n",
    "            model.add(samples_hv, labels)\n",
    "\n",
    "    accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.normalize()\n",
    "\n",
    "        # Open the three output files before the testing loop\n",
    "        with open('sample.mem', 'w') as f_samples, \\\n",
    "             open('label.mem', 'w') as f_labels, \\\n",
    "             open('class_weights.mem', 'w') as f_weights:\n",
    "\n",
    "            print(\"\\nWriting class weights to class_weights.mem...\")\n",
    "            # Get the model's weights and convert to half-precision (FP16) on the CPU\n",
    "            weights_fp16 = model.weight.cpu().half()\n",
    "            \n",
    "            # Iterate through each weight value in the model's weight tensor\n",
    "            for w in weights_fp16.flatten():\n",
    "                # Pack the float16 value into 2 bytes (big-endian) and convert to hex\n",
    "                hex_weight = struct.pack('>e', w.item()).hex()\n",
    "                f_weights.write(f\"{hex_weight}\\n\")\n",
    "            print(\"Finished writing weights.\")\n",
    "\n",
    "            # Process the test dataset to write samples and labels\n",
    "            for samples, labels in tqdm(test_ld, desc=\"Testing and Writing Files\"):\n",
    "                samples = samples.to(device)\n",
    "                samples_hv = encode(samples)\n",
    "\n",
    "                # Iterate through each sample and label in the current batch\n",
    "                for i in range(samples_hv.size(0)):\n",
    "                    single_sample_hv = samples_hv[i]\n",
    "                    single_label = labels[i]\n",
    "\n",
    "                    # --- Binarize HV: bipolar -1/+1 to binary 1/0 ---\n",
    "                    single_sample_hv_bin = (single_sample_hv == -1).to(torch.uint8)\n",
    "                    \n",
    "                    # Flip the order of the bits (LSB <-> MSB)\n",
    "                    single_sample_hv_bin = torch.flip(single_sample_hv_bin, dims=[0])\n",
    "                    \n",
    "                    # Convert the binary sample tensor to a hex string and write to file\n",
    "                    hex_sample_str = binary_tensor_to_hex_str(single_sample_hv_bin)\n",
    "                    f_samples.write(f\"{hex_sample_str}\\n\")\n",
    "\n",
    "                    # Write the corresponding label to its file\n",
    "                    f_labels.write(f\"{single_label.item()}\\n\")\n",
    "\n",
    "                \n",
    "                \n",
    "                samples_hv = samples_hv.to(device)\n",
    "                outputs = model(samples_hv, \"dot\")\n",
    "                accuracy.update(outputs.cpu(), labels)\n",
    "\n",
    "        print(\"Finished writing samples and labels.\")\n",
    "\n",
    "    acc = accuracy.compute().item() * 100\n",
    "    print(f\"Testing accuracy for run {run + 1}: {acc:.3f}%\")\n",
    "    accuracies.append(acc)\n",
    "\n",
    "min_acc = min(accuracies)\n",
    "max_acc = max(accuracies)\n",
    "avg_acc = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(f\"\\nMinimum accuracy: {min_acc:.3f}%\")\n",
    "print(f\"Maximum accuracy: {max_acc:.3f}%\")\n",
    "print(f\"Average accuracy: {avg_acc:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
